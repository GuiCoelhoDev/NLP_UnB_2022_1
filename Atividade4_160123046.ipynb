{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade4_160123046.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQe993Zs+iGOSfW9cm8l/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guico3lho/NLP_UnB_2022_1/blob/atividade4/Atividade4_160123046.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-qQvBxbBArFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfhWqquatVhs"
      },
      "outputs": [],
      "source": [
        "def funcAtivacao(net, tipo,threshold=1):\n",
        "    if tipo == 'degrau':\n",
        "        if net >= threshold:\n",
        "            y = 1\n",
        "        else:\n",
        "            y = 0\n",
        "    elif tipo == 'sinal':\n",
        "        if net >= 0:\n",
        "            y = 1\n",
        "        else:\n",
        "            y = -1\n",
        "    elif tipo == 'sinoidal':\n",
        "        y = 1/(1+math.exp(-net))\n",
        "    else:\n",
        "        y = 'Tipo inv√°lido'\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    lr = 0.05\n",
        "    data_xor = [[0,0],[0,1],[1,0],[1,1]]\n",
        "    labels = [0,1,1,0]\n",
        "\n",
        "    layer1_pesos = np.random.randn(4) # w11,w12,w13,w14\n",
        "    layer2_pesos = np.random.randn(2) # w21,w22\n",
        "    epochs = 0\n",
        "    while epochs < 10:\n",
        "        print(\"Epoca:\", epochs)\n",
        "        for i,x in enumerate(data_xor):\n",
        "            net1 = data_xor[i][0]*layer1_pesos[0] + data_xor[i][1]*layer1_pesos[2] # x1*w11 + x2*w13\n",
        "            net2 = data_xor[i][0]*layer1_pesos[1] + data_xor[i][1]*layer1_pesos[3] # x1*w12 + x2*w14\n",
        "\n",
        "            O1 = funcAtivacao(net1,'sinoidal')\n",
        "            O2 = funcAtivacao(net2,'sinoidal')\n",
        "\n",
        "            net3 = O1*layer2_pesos[0]+O2*layer2_pesos[1] # O1*W21 + O2*W22\n",
        "\n",
        "\n",
        "            y = funcAtivacao(net3, 'sinoidal')\n",
        "\n",
        "            loss = (y-labels[i])**2\n",
        "            print(\"Loss:\", loss)\n",
        "            # para cada neuronio na camada de saida\n",
        "            del3 = y*(1-y)*(y-labels[i])\n",
        "\n",
        "            # para cada neuronio na camada oculta\n",
        "            del1 = O1*(1-O1)*del3*layer2_pesos[0]\n",
        "            del2 = O2*(1-O2)*del3*layer2_pesos[1]\n",
        "\n",
        "            # atualizando pesos da rede camada 2\n",
        "            delta = lr*del3*y\n",
        "            layer2_pesos[0] += delta\n",
        "            layer2_pesos[1] += delta\n",
        "\n",
        "            # atualizando pesos da rede camada 1\n",
        "            delta = lr*del1*O1\n",
        "            layer1_pesos[0] += delta\n",
        "            layer1_pesos[3] += delta\n",
        "\n",
        "            delta = lr*del2*O2\n",
        "            layer1_pesos[1] += delta\n",
        "            layer1_pesos[3] += delta\n",
        "\n",
        "\n",
        "\n",
        "        epochs += 1\n",
        "           "
      ],
      "metadata": {
        "id": "y0LNFHycApOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Deu ruim :)\")\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy5X3knSAtjK",
        "outputId": "e774c4f0-c970-45e6-d853-cbf53fc00cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deu ruim :)\n",
            "Epoca: 0\n",
            "Loss: 0.29808526906584404\n",
            "Loss: 0.20052238410806042\n",
            "Loss: 0.21627756162743744\n",
            "Loss: 0.2908971085675062\n",
            "Epoca: 1\n",
            "Loss: 0.29839836555595295\n",
            "Loss: 0.20023747251395857\n",
            "Loss: 0.21606894481080435\n",
            "Loss: 0.29117196147755875\n",
            "Epoca: 2\n",
            "Loss: 0.2987137121761708\n",
            "Loss: 0.1999508548679927\n",
            "Loss: 0.21585901352422668\n",
            "Loss: 0.291448831606646\n",
            "Epoca: 3\n",
            "Loss: 0.29903132709697405\n",
            "Loss: 0.1996625214609982\n",
            "Loss: 0.2156477592342733\n",
            "Loss: 0.2917277361193826\n",
            "Epoca: 4\n",
            "Loss: 0.2993512286528021\n",
            "Loss: 0.19937246254515303\n",
            "Loss: 0.21543517335365672\n",
            "Loss: 0.2920086923532273\n",
            "Epoca: 5\n",
            "Loss: 0.2996734353435859\n",
            "Loss: 0.1990806683342852\n",
            "Loss: 0.21522124724101668\n",
            "Loss: 0.2922917178204848\n",
            "Epoca: 6\n",
            "Loss: 0.29999796583628485\n",
            "Loss: 0.19878712900419404\n",
            "Loss: 0.21500597220070808\n",
            "Loss: 0.29257683021033\n",
            "Epoca: 7\n",
            "Loss: 0.3003248389664353\n",
            "Loss: 0.19849183469298737\n",
            "Loss: 0.21478933948259066\n",
            "Loss: 0.2928640473908593\n",
            "Epoca: 8\n",
            "Loss: 0.3006540737397111\n",
            "Loss: 0.19819477550143527\n",
            "Loss: 0.21457134028182465\n",
            "Loss: 0.29315338741116537\n",
            "Epoca: 9\n",
            "Loss: 0.30098568933349323\n",
            "Loss: 0.197895941493338\n",
            "Loss: 0.21435196573866963\n",
            "Loss: 0.2934448685034375\n"
          ]
        }
      ]
    }
  ]
}